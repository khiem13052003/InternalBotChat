services:
  mlc:
    image: dustynv/mlc:0.20.0-r36.4.0
    container_name: mlc
    # Jetson thường dùng runtime nvidia; nếu docker của bạn hỗ trợ --gpus, có thể thay
    runtime: nvidia
    privileged: true
    stdin_open: false
    tty: false
    ipc: host
    shm_size: '16g'                # giữ hoặc điều chỉnh (tối thiểu 1-2g)
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - TZ=Asia/Ho_Chi_Minh
      - FORCE_CUDA=1
    volumes:
      - ./models:/home/khiem/Projects/one/models                       # nơi bạn lưu model
      - ~/.cache/huggingface:/khiem/.cache/huggingface
      - ./data:/home/khiem/Projects/one/data
      - /etc/localtime:/etc/localtime:ro
    working_dir: /root
    # START SERVER AUTOMATICALLY: chỉnh model path & overrides phù hợp
    command:
      - mlc_llm
      - serve
      - /home/khiem/Projects/one/models/mlc/tinyllama-1.1b-q4f16-MLC
      - --host
      - 0.0.0.0
      - --port
      - "8000"
      - --overrides
      - "max_num_sequence=1;max_total_seq_length=256;prefill_chunk_size=64;gpu_memory_utilization=0.6"
    ports:
      - "8000:8000"
    restart: unless-stopped
    ulimits:
      memlock: -1
      nofile: 65536

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://127.0.0.1:8000/v1/models || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
